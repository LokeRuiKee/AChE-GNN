{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LokeRuiKee/AChE-GNN/blob/main/DC_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install rdkit\n",
        "!pip install colorama\n",
        "!pip install deepchem"
      ],
      "metadata": {
        "id": "M5mizX0BB8bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "JmEc6EbDAdos",
        "outputId": "6b190391-b478-43a2-dfff-c61ce8da2749"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for SPS. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for AvgIpc. Feature removed!\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
            "WARNING:deepchem.models.torch_models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/usr/local/lib/python3.10/dist-packages/deepchem/models/torch_models/__init__.py)\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
            "WARNING:deepchem.models:Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import time\n",
        "import copy\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
        "\n",
        "import deepchem as dc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWc_He9HAdot"
      },
      "outputs": [],
      "source": [
        "def rmse(estimator, X_eval, y_eval):\n",
        "    y_hat = estimator.predict(X_eval)\n",
        "    return np.sqrt(mean_squared_error(y_eval.flatten(), y_hat.flatten()))\n",
        "\n",
        "\n",
        "def r2(estimator, X_eval, y_eval):\n",
        "    y_hat = estimator.predict(X_eval)\n",
        "    return r2_score(y_eval.flatten(), y_hat.flatten())\n",
        "\n",
        "\n",
        "def peason_r(estimator, X_eval, y_eval):\n",
        "    y_hat = estimator.predict(X_eval)\n",
        "    return np.corrcoef(y_eval.flatten(), y_hat.flatten())[0, 1]\n",
        "\n",
        "\n",
        "def peason_r_metric(y_true, y_pred):\n",
        "    return np.corrcoef(y_true.flatten(), y_pred.flatten())[0, 1]\n",
        "\n",
        "peason_r_score = make_scorer(peason_r_metric)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt6jAVGKDIip",
        "outputId": "e30158e0-7d43-44f3-d215-d9a4cb55d8f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppnt4diOAdou"
      },
      "source": [
        "# Create train/test datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import deepchem as dc\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/Dataset/tx2c00283_si_002/SupplementalFiles/Human_dataset_continuous.xlsx\"\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Specify the columns\n",
        "smiles_column = \"SMILES\"\n",
        "y_column = \"continuous-value\"\n",
        "\n",
        "# Split the data into features and target\n",
        "X = df[smiles_column]\n",
        "y = df[y_column]\n",
        "\n",
        "# Split the data into training+validation and test sets\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split the training+validation set into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
        "\n",
        "# Concatenate the features and target for each set\n",
        "train_data = pd.concat([X_train, y_train], axis=1)\n",
        "val_data = pd.concat([X_val, y_val], axis=1)\n",
        "test_data = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "# Define the directory and file paths\n",
        "base_dir = \"/content/drive/MyDrive/Colab Notebooks/Dataset/data/process/continuous\"\n",
        "train_file = os.path.join(base_dir, \"pdY_train.csv\")\n",
        "val_file = os.path.join(base_dir, \"pdY_val.csv\")\n",
        "test_file = os.path.join(base_dir, \"pdY_test.csv\")\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Save the data to CSV files\n",
        "train_data.to_csv(train_file, index=False)\n",
        "val_data.to_csv(val_file, index=False)\n",
        "test_data.to_csv(test_file, index=False)"
      ],
      "metadata": {
        "id": "jjLbZ-ybCZWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sgroP0JAdov"
      },
      "outputs": [],
      "source": [
        "train_file = \"/content/drive/MyDrive/Colab Notebooks/Dataset/data/process/continuous/pdY_train.csv\"\n",
        "test_file = \"/content/drive/MyDrive/Colab Notebooks/Dataset/data/process/continuous/pdY_test.csv\"\n",
        "\n",
        "tasks = [\"continuous-value\"]\n",
        "ntasks = len(tasks)\n",
        "featurizer_func = dc.feat.ConvMolFeaturizer()\n",
        "loader = dc.data.CSVLoader(tasks=tasks, feature_field='SMILES', featurizer=featurizer_func)\n",
        "\n",
        "train_dataset = loader.create_dataset(train_file)\n",
        "test_dataset = loader.create_dataset(test_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neYfaNSiAdov"
      },
      "source": [
        "# Default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT6Jgmc-Adov",
        "outputId": "f45ae33c-b16f-435c-dbae-d06ed31ac449"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE: 0.44364540879546344\n",
            "Train Pearson's R: 0.9581131093057201\n",
            "Test RMSE: 0.8857301805576576\n",
            "Test Pearson's R: 0.7992666551549412\n"
          ]
        }
      ],
      "source": [
        "model = dc.models.GraphConvModel(ntasks, mode='regression', model_dir=\"models/graph_conv_01\")\n",
        "model.fit(train_dataset, nb_epoch=50)\n",
        "\n",
        "print(\"Train RMSE:\", rmse(model, train_dataset, train_dataset.y))\n",
        "print(\"Train Pearson's R:\", peason_r(model, train_dataset, train_dataset.y))\n",
        "\n",
        "print(\"Test RMSE:\", rmse(model, test_dataset, test_dataset.y))\n",
        "print(\"Test Pearson's R:\", peason_r(model, test_dataset, test_dataset.y))\n",
        "\n",
        "#pickle.dump(model, open(\"models/graph_conv_01.pkl\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYEIEGpNAdov",
        "outputId": "1c1ecc6d-0e8e-4cee-941e-f9706f5eb7b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE: 0.44364540879546344\n",
            "Train Pearson's R: 0.9581131093057201\n",
            "Test RMSE: 0.8857301805576576\n",
            "Test Pearson's R: 0.7992666551549412\n"
          ]
        }
      ],
      "source": [
        "model = dc.models.GraphConvModel(ntasks, mode='regression', model_dir=\"models/graph_conv_01\")\n",
        "model.restore()\n",
        "\n",
        "print(\"Train RMSE:\", rmse(model, train_dataset, train_dataset.y))\n",
        "print(\"Train Pearson's R:\", peason_r(model, train_dataset, train_dataset.y))\n",
        "\n",
        "print(\"Test RMSE:\", rmse(model, test_dataset, test_dataset.y))\n",
        "print(\"Test Pearson's R:\", peason_r(model, test_dataset, test_dataset.y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSqttAGnAdov"
      },
      "source": [
        "## `graph_conv_layers = [64, 64, 64]`, `dense_layer_size=128`, `dropout=0`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to fix TypeError: 'Metric' object is not subscriptable in ori code\n",
        "\n",
        "import deepchem as dc\n",
        "\n",
        "# Define the metric\n",
        "metric = dc.metrics.Metric(dc.metrics.rms_score)\n",
        "\n",
        "# Create a list of metrics if needed\n",
        "metrics = [metric]\n",
        "\n",
        "# Define the callback with the correct metric handling\n",
        "callback = dc.models.ValidationCallback(test_dataset, 100, metrics=metrics)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(train_dataset, nb_epoch=100, callbacks=[callback])\n",
        "\n",
        "# Calculate and print the RMSE\n",
        "train_rmse = metric.compute_metric(model.predict(train_dataset), train_dataset.y)\n",
        "test_rmse = metric.compute_metric(model.predict(test_dataset), test_dataset.y)\n",
        "\n",
        "print(\"Train RMSE:\", train_rmse)\n",
        "print(\"Test RMSE:\", test_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJF6QkIRJwMx",
        "outputId": "ea51a5c7-90bc-467e-a75a-2f568aadaa49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 200 validation: rms_score=3.25054\n",
            "Step 300 validation: rms_score=2.31172\n",
            "Step 400 validation: rms_score=1.61092\n",
            "Step 500 validation: rms_score=1.26434\n",
            "Step 600 validation: rms_score=1.15431\n",
            "Step 700 validation: rms_score=1.10221\n",
            "Step 800 validation: rms_score=1.05446\n",
            "Step 900 validation: rms_score=1.02411\n",
            "Step 1000 validation: rms_score=0.99771\n",
            "Step 1100 validation: rms_score=0.989117\n",
            "Step 1200 validation: rms_score=0.971996\n",
            "Step 1300 validation: rms_score=0.950726\n",
            "Step 1400 validation: rms_score=0.956249\n",
            "Step 1500 validation: rms_score=0.941443\n",
            "Step 1600 validation: rms_score=0.937108\n",
            "Step 1700 validation: rms_score=0.940545\n",
            "Step 1800 validation: rms_score=0.939824\n",
            "Step 1900 validation: rms_score=0.941739\n",
            "Step 2000 validation: rms_score=0.943693\n",
            "Step 2100 validation: rms_score=0.931249\n",
            "Step 2200 validation: rms_score=0.913999\n",
            "Step 2300 validation: rms_score=0.926782\n",
            "Step 2400 validation: rms_score=0.907563\n",
            "Step 2500 validation: rms_score=0.909721\n",
            "Step 2600 validation: rms_score=0.925517\n",
            "Step 2700 validation: rms_score=0.916824\n",
            "Step 2800 validation: rms_score=0.914419\n",
            "Step 2900 validation: rms_score=0.912011\n",
            "Step 3000 validation: rms_score=0.90201\n",
            "Step 3100 validation: rms_score=0.921239\n",
            "Step 3200 validation: rms_score=0.909694\n",
            "Step 3300 validation: rms_score=0.904366\n",
            "Step 3400 validation: rms_score=0.900515\n",
            "Step 3500 validation: rms_score=0.896907\n",
            "Step 3600 validation: rms_score=0.901089\n",
            "Train RMSE: 0.37144376933490914\n",
            "Test RMSE: 0.9010889858024458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train RMSE:\", rmse(model, train_dataset, train_dataset.y))\n",
        "print(\"Train Pearson's R:\", peason_r(model, train_dataset, train_dataset.y))\n",
        "\n",
        "print(\"Test RMSE:\", rmse(model, test_dataset, test_dataset.y))\n",
        "print(\"Test Pearson's R:\", peason_r(model, test_dataset, test_dataset.y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ory7OIktLPTr",
        "outputId": "c624e36b-4c4b-4cee-f0c6-4587068d1b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE: 0.37144376933490914\n",
            "Train Pearson's R: 0.9697497545140984\n",
            "Test RMSE: 0.9010889858024458\n",
            "Test Pearson's R: 0.7983182892311323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train RMSE: 0.37144376933490914\n",
        "Train Pearson's R: 0.9697497545140984\n",
        "Test RMSE: 0.9010889858024458\n",
        "Test Pearson's R: 0.7983182892311323\n",
        "\n",
        "significant high of RMSE in test compared to train shows overfitting."
      ],
      "metadata": {
        "id": "jgSTVVRGLefN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "from rdkit import Chem\n",
        "\n",
        "# example test case from validation set\n",
        "# correct value = 7.185087\n",
        "\n",
        "# Define a new SMILES string\n",
        "new_smiles = \"Cc1cc(=O)oc2cc(OCc3cc[n+](Cc4ccccc4F)cc3)ccc12\"\n",
        "\n",
        "# Create a ConvMolFeaturizer\n",
        "featurizer = dc.feat.ConvMolFeaturizer()\n",
        "\n",
        "# Convert the SMILES string to the format expected by the model\n",
        "new_mol = Chem.MolFromSmiles(new_smiles)\n",
        "new_data = featurizer.featurize([new_mol])\n",
        "\n",
        "# Create a Dataset object from the new data\n",
        "new_dataset = dc.data.NumpyDataset(new_data)\n",
        "\n",
        "# Predict the class probabilities for the new data\n",
        "new_pred_probs = model.predict(new_dataset)\n",
        "\n",
        "# Select the probabilities of the first task\n",
        "new_pred_probs = new_pred_probs[:, 0]\n",
        "\n",
        "print(\"Predicted probs for new data:\", new_pred_probs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDkmE3umLzrp",
        "outputId": "f924d294-e49b-4a2e-da7e-034c3c5cfc89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted probs for new data: 6.725976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note to self: what does the continuous value means"
      ],
      "metadata": {
        "id": "-Obb1SYhMyhl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dxM35D7Adov"
      },
      "outputs": [],
      "source": [
        "#ori code (output TypeError: 'Metric' object is not subscriptable)\n",
        "\n",
        "# batch_size = 64\n",
        "# batches_per_epoch = 600/batch_size\n",
        "# learning_rate = dc.models.optimizers.ExponentialDecay(0.0001, 0.9, batches_per_epoch)\n",
        "\n",
        "# model = dc.models.GraphConvModel(ntasks,\n",
        "#                                  graph_conv_layers=[64, 64, 64],\n",
        "#                                  dense_layer_size=128,\n",
        "#                                  dropout=0.,\n",
        "#                                  batch_normalize=True,\n",
        "#                                  mode='regression',\n",
        "#                                  batch_size=batch_size,\n",
        "#                                  learning_rate=learning_rate)\n",
        "\n",
        "# metric = dc.metrics.Metric(dc.metrics.rms_score)\n",
        "# callback = dc.models.ValidationCallback(test_dataset, 100, metric)\n",
        "# model.fit(train_dataset, nb_epoch=100, callbacks=callback)\n",
        "\n",
        "# print(\"Train RMSE:\", rmse(model, train_dataset, train_dataset.y))\n",
        "# print(\"Train Pearson's R:\", peason_r(model, train_dataset, train_dataset.y))\n",
        "\n",
        "# print(\"Test RMSE:\", rmse(model, test_dataset, test_dataset.y))\n",
        "# print(\"Test Pearson's R:\", peason_r(model, test_dataset, test_dataset.y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "095tdQX3Adow"
      },
      "outputs": [],
      "source": [
        "# model = dc.models.GraphConvModel(ntasks, mode='regression')\n",
        "# model.restore()\n",
        "\n",
        "# print(\"Train RMSE:\", rmse(model, train_dataset, train_dataset.y))\n",
        "# print(\"Train Pearson's R:\", peason_r(model, train_dataset, train_dataset.y))\n",
        "\n",
        "# print(\"Test RMSE:\", rmse(model, test_dataset, test_dataset.y))\n",
        "# print(\"Test Pearson's R:\", peason_r(model, test_dataset, test_dataset.y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoZMEpu0Adow"
      },
      "source": [
        "##  `graph_conv_layers = [128, 128, 128,  128, 128]`, `dense_layer_size=256`, `dropout=0.0`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aoDGPFYNDAU",
        "outputId": "74bcf4d3-6fb1-4cd7-ddb0-f799a4d8a2bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 100 validation: rms_score=1.44599\n",
            "Step 200 validation: rms_score=1.41144\n",
            "Step 300 validation: rms_score=1.23664\n",
            "Step 400 validation: rms_score=1.04291\n",
            "Step 500 validation: rms_score=0.940565\n",
            "Step 600 validation: rms_score=0.906373\n",
            "Step 700 validation: rms_score=0.846281\n",
            "Step 800 validation: rms_score=0.860708\n",
            "Step 900 validation: rms_score=0.856451\n",
            "Step 1000 validation: rms_score=0.806116\n",
            "Step 1100 validation: rms_score=0.81079\n",
            "Step 1200 validation: rms_score=0.826208\n",
            "Step 1300 validation: rms_score=0.824628\n",
            "Step 1400 validation: rms_score=0.815268\n",
            "Step 1500 validation: rms_score=0.823608\n",
            "Step 1600 validation: rms_score=0.844555\n",
            "Step 1700 validation: rms_score=0.822599\n",
            "Step 1800 validation: rms_score=0.82032\n",
            "Step 1900 validation: rms_score=0.834175\n",
            "Step 2000 validation: rms_score=0.80763\n",
            "Step 2100 validation: rms_score=0.819438\n",
            "Step 2200 validation: rms_score=0.807328\n",
            "Step 2300 validation: rms_score=0.810937\n",
            "Step 2400 validation: rms_score=0.783598\n",
            "Step 2500 validation: rms_score=0.803996\n",
            "Step 2600 validation: rms_score=0.800466\n",
            "Step 2700 validation: rms_score=0.816946\n",
            "Step 2800 validation: rms_score=0.805242\n",
            "Step 2900 validation: rms_score=0.77715\n",
            "Step 3000 validation: rms_score=0.818947\n",
            "Step 3100 validation: rms_score=0.807703\n",
            "Step 3200 validation: rms_score=0.811173\n",
            "Step 3300 validation: rms_score=0.825685\n",
            "Step 3400 validation: rms_score=0.815233\n",
            "Step 3500 validation: rms_score=0.800044\n",
            "Train RMSE: 0.2707803892622269\n",
            "Train Pearson's R: 0.9835095881297987\n",
            "Test RMSE: 0.8000436601541736\n",
            "Test Pearson's R: 0.8398306288115689\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define the model\n",
        "model = dc.models.GraphConvModel(\n",
        "    n_tasks=ntasks,\n",
        "    graph_conv_layers=[128, 128, 128, 128, 128],\n",
        "    dense_layer_size=256,\n",
        "    dropout=0.0,\n",
        "    batch_normalize=True,\n",
        "    mode='regression',\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "# Define the metric\n",
        "metric = dc.metrics.Metric(dc.metrics.rms_score)\n",
        "metrics = [metric]\n",
        "\n",
        "# Create the callback\n",
        "callback = dc.models.ValidationCallback(test_dataset, 100, metrics=metrics)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(train_dataset, nb_epoch=100, callbacks=[callback])\n",
        "\n",
        "print(\"Train RMSE:\", rmse(model, train_dataset, train_dataset.y))\n",
        "print(\"Train Pearson's R:\", peason_r(model, train_dataset, train_dataset.y))\n",
        "\n",
        "print(\"Test RMSE:\", rmse(model, test_dataset, test_dataset.y))\n",
        "print(\"Test Pearson's R:\", peason_r(model, test_dataset, test_dataset.y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bT0Sf5nTAdow"
      },
      "outputs": [],
      "source": [
        "# ori\n",
        "model = dc.models.GraphConvModel(ntasks,\n",
        "                                 graph_conv_layers=[128, 128, 128, 128, 128],\n",
        "                                 dense_layer_size=256,\n",
        "                                 dropout=0.0,\n",
        "                                 batch_normalize=True,\n",
        "                                 mode='regression',\n",
        "                                 batch_size=64)\n",
        "\n",
        "metric = dc.metrics.Metric(dc.metrics.rms_score)\n",
        "callback = dc.models.ValidationCallback(test_dataset, 100, metric)\n",
        "model.fit(train_dataset, nb_epoch=100, callbacks=callback)\n",
        "\n",
        "print(\"Train RMSE:\", rmse(model, train_dataset, train_dataset.y))\n",
        "print(\"Train Pearson's R:\", peason_r(model, train_dataset, train_dataset.y))\n",
        "\n",
        "print(\"Test RMSE:\", rmse(model, test_dataset, test_dataset.y))\n",
        "print(\"Test Pearson's R:\", peason_r(model, test_dataset, test_dataset.y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUl19Wl0Adow"
      },
      "outputs": [],
      "source": [
        "# # ori\n",
        "# y_test_pred = model.predict(test_dataset)\n",
        "# test_pred_df = pd.DataFrame({\"smiles\": test_dataset.ids, \"actual\": test_dataset.y.flatten(), \"pred\": y_test_pred.flatten()})\n",
        "# test_pred_df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/Dataset/data/process/continuous/results/test_pred.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_gVDRkJAdox"
      },
      "source": [
        "## graph_conv_layers = [64, 128,], dense_layer_size=128, dropout=0.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = dc.models.GraphConvModel(ntasks,\n",
        "                                 graph_conv_layers=[512, 512, 512],\n",
        "                                 dense_layer_size=512,\n",
        "                                 dropout=0.,\n",
        "                                 batch_normalize=True,\n",
        "                                 mode='regression',\n",
        "                                 batch_size=64)\n",
        "\n",
        "# Define the metric\n",
        "metric = dc.metrics.Metric(dc.metrics.rms_score)\n",
        "metrics = [metric]\n",
        "\n",
        "# Create the callback\n",
        "callback = dc.models.ValidationCallback(test_dataset, 100, metrics=metrics)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(train_dataset, nb_epoch=100, callbacks=[callback])\n",
        "\n",
        "print(\"Train RMSE:\", rmse(model, train_dataset, train_dataset.y))\n",
        "print(\"Train Pearson's R:\", peason_r(model, train_dataset, train_dataset.y))\n",
        "\n",
        "print(\"Test RMSE:\", rmse(model, test_dataset, test_dataset.y))\n",
        "print(\"Test Pearson's R:\", peason_r(model, test_dataset, test_dataset.y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKDmJLNGZvPr",
        "outputId": "2b09590e-3037-4fb1-ca61-0fff637c4cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 100 validation: rms_score=3.47723\n",
            "Step 200 validation: rms_score=4.7227\n",
            "Step 300 validation: rms_score=3.30143\n",
            "Step 400 validation: rms_score=1.78038\n",
            "Step 500 validation: rms_score=1.44158\n",
            "Step 600 validation: rms_score=0.987652\n",
            "Step 700 validation: rms_score=0.925598\n",
            "Step 800 validation: rms_score=0.868425\n",
            "Step 900 validation: rms_score=0.846627\n",
            "Step 1000 validation: rms_score=0.810435\n",
            "Step 1100 validation: rms_score=0.833678\n",
            "Step 1200 validation: rms_score=0.886114\n",
            "Step 1300 validation: rms_score=0.837756\n",
            "Step 1400 validation: rms_score=0.851968\n",
            "Step 1500 validation: rms_score=0.803544\n",
            "Step 1600 validation: rms_score=0.801711\n",
            "Step 1700 validation: rms_score=0.80513\n",
            "Step 1800 validation: rms_score=0.796152\n",
            "Step 1900 validation: rms_score=0.829404\n",
            "Step 2000 validation: rms_score=0.78321\n",
            "Step 2100 validation: rms_score=0.810472\n",
            "Step 2200 validation: rms_score=0.794862\n",
            "Step 2300 validation: rms_score=0.837624\n",
            "Step 2400 validation: rms_score=0.803296\n",
            "Step 2500 validation: rms_score=0.799778\n",
            "Step 2600 validation: rms_score=0.788569\n",
            "Step 2700 validation: rms_score=0.788082\n",
            "Step 2800 validation: rms_score=0.791796\n",
            "Step 2900 validation: rms_score=0.799341\n",
            "Step 3000 validation: rms_score=0.782426\n",
            "Step 3100 validation: rms_score=0.77298\n",
            "Step 3200 validation: rms_score=0.804188\n",
            "Step 3300 validation: rms_score=0.794906\n",
            "Step 3400 validation: rms_score=0.848472\n",
            "Step 3500 validation: rms_score=0.789231\n",
            "Train RMSE: 0.26427958697486115\n",
            "Train Pearson's R: 0.9862316030811469\n",
            "Test RMSE: 0.7892308743297779\n",
            "Test Pearson's R: 0.8460360447845789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TsaKoxAAdox"
      },
      "outputs": [],
      "source": [
        "# ori\n",
        "model = dc.models.GraphConvModel(ntasks,\n",
        "                                 graph_conv_layers=[512, 512, 512],\n",
        "                                 dense_layer_size=512,\n",
        "                                 dropout=0.,\n",
        "                                 batch_normalize=True,\n",
        "                                 mode='regression',\n",
        "                                 batch_size=64)\n",
        "\n",
        "metric = dc.metrics.Metric(dc.metrics.rms_score)\n",
        "callback = dc.models.ValidationCallback(test_dataset, 100, metric)\n",
        "model.fit(train_dataset, nb_epoch=50, callbacks=callback)\n",
        "\n",
        "print(\"Train RMSE:\", rmse(model, train_dataset, train_dataset.y))\n",
        "print(\"Train Pearson's R:\", peason_r(model, train_dataset, train_dataset.y))\n",
        "\n",
        "print(\"Test RMSE:\", rmse(model, test_dataset, test_dataset.y))\n",
        "print(\"Test Pearson's R:\", peason_r(model, test_dataset, test_dataset.y))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inference with model 3\n",
        "from rdkit import Chem\n",
        "\n",
        "# example test case from validation set\n",
        "# correct value = 7.185087\n",
        "\n",
        "# Define a new SMILES string\n",
        "new_smiles = \"Cc1cc(=O)oc2cc(OCc3cc[n+](Cc4ccccc4F)cc3)ccc12\"\n",
        "\n",
        "# Create a ConvMolFeaturizer\n",
        "featurizer = dc.feat.ConvMolFeaturizer()\n",
        "\n",
        "# Convert the SMILES string to the format expected by the model\n",
        "new_mol = Chem.MolFromSmiles(new_smiles)\n",
        "new_data = featurizer.featurize([new_mol])\n",
        "\n",
        "# Create a Dataset object from the new data\n",
        "new_dataset = dc.data.NumpyDataset(new_data)\n",
        "\n",
        "# Predict the class probabilities for the new data\n",
        "new_pred_probs = model.predict(new_dataset)\n",
        "\n",
        "# Select the probabilities of the first task\n",
        "new_pred_probs = new_pred_probs[:, 0]\n",
        "\n",
        "print(\"Predicted probs for new data:\", new_pred_probs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0enlHeyQkEzF",
        "outputId": "7a8f24ca-d79d-4256-f765-6735055388a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted probs for new data: 7.150532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to write the comparison of actual and predicted value into csv file.\n",
        "\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "y_test_pred = model.predict(test_dataset)\n",
        "test_pred_df = pd.DataFrame({\"smiles\": test_dataset.ids, \"actual\": test_dataset.y.flatten(), \"pred\": y_test_pred.flatten()})\n",
        "\n",
        "# Define Malaysia timezone\n",
        "malaysia_tz = pytz.timezone('Asia/Kuala_Lumpur')\n",
        "\n",
        "# Get the current date and time in Malaysia timezone\n",
        "current_time_malaysia = datetime.now(malaysia_tz).strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Create the filename with the date and time appended\n",
        "filename = f\"test_pred_{current_time_malaysia}.csv\"\n",
        "\n",
        "# Save the DataFrame to the specified path with the new filename\n",
        "test_pred_df.to_csv(f\"/content/drive/MyDrive/Colab Notebooks/Dataset/data/process/continuous/results/{filename}\", index=False)"
      ],
      "metadata": {
        "id": "sP5yawrxmhu_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}